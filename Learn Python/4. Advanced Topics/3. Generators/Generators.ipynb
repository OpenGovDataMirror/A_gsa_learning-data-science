{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Objectives\n",
    "By the end of this lesson, you will be able to:\n",
    "- Understand the generator use case\n",
    "- Construct a generator\n",
    "- Yield data from, and send data to, generator functions\n",
    "- Use generator comprehensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    " - [Why Generators?](#why)\n",
    " - [Creating a Generator](#generator)\n",
    " - [Generator Comprehensions](#gc)\n",
    " - [Takeaways](#takeaways)\n",
    " - [What's Next](#next)\n",
    " - [Applications](#applications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='why' ></a>\n",
    "## Why Generators?\n",
    "\n",
    "#### The Python Function as a Subroutine\n",
    "As we know, Python functions `return` a value. But think for a moment about why we say \"`return`.\" You might recall that, when we call a function, code execution starts at the function's first line and continues until we encounter a `return` statement, `Exception`, or the end of the function, in which case `None` is actually returned. Then, once our function is done, all of its local variables (its state) are lost and we **return** the program to the point at which the function was called. Any new calls to the function would repeat this process. In computer programming, this process is known as a [subroutine](https://en.wikipedia.org/wiki/Subroutine).\n",
    "\n",
    "That's all fine and dandy, but once you start working with larger streams of data, there will be times when you want a function that can *yield a series of values* instead of returning a single value and then wiping its state. For a function to do this, it would need to be able to remember its state between each yield.\n",
    "\n",
    "Why did I italicize *yield a series of values* in the paragraph above? I did so because our hypothetical function wouldn't `return` like a typical Python function. As a subroutine, a function `return` means that the function is returning control of code execution to the point in our program where the function was called. `yield` - the Python keyword for defining generators - makes that transfer of control temporary, leaving our function's state intact and expectant of regaining control again in the future.\n",
    "\n",
    "**Functions that `yield` a series of values are called generators in Python.** Before generators, creating large sequences of data required code that both generated values and kept track of the function's state between calls. Since generators remember their state so to speak, yielding a series of values has become much easier.\n",
    "\n",
    "#### Generators are a Subtype of Iterators\n",
    "Generators can yield a series of values because they're functions that act like iterators. In fact, they're a subtype of iterators. But what's an iterator? Let's unpack that real quick:\n",
    "\n",
    "> **Iteration** is the process of doing something to each item in a sequence of items. Using a loop is an example of iteration. This term is not specific to Python (it's basis is in mathematics).\n",
    "\n",
    "> **Iterable** and **iterator** have specific meanings in Python:\n",
    "\n",
    ">> An **iterator** is an object representing a stream of data; this object returns the data one element at a time with the `__next__` method until there are no more elements in the stream, in which case the object raises the `StopIteration` exception.\n",
    "\n",
    ">> An **iterable** is an object that has an `__iter__` method, which returns an iterator, or which defines a  `__getitem__` method that can take sequential indexes starting from zero, raising an `IndexError` when the index exceeds the length of the sequence.\n",
    "\n",
    ">> In short, **an iterable is an object that you can get an iterator from**.\n",
    "\n",
    "**Iterators are great because they save memory.** When you instantiate an iterator, the object doesn't contain the whole sequence in memory and will only compute the values from the sequence when you ask for them. This is known as [lazy evaluation](https://en.wikipedia.org/wiki/Lazy_evaluation) and it's a boon when you're working with large (or infinite!) sequences of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an Iterator to Work with Prime Numbers\n",
    "To see iterators in action, we'll write some code to get the sum of all of the prime numbers smaller than a given number. We'll do this two ways:  with and without an iterator. But first, let's define a helper function that tests whether a given number is prime or not using the [trial division primality test](https://en.wikipedia.org/wiki/Primality_test#Simple_methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primality_test(number):\n",
    "    \"\"\"\n",
    "    Return a boolean after peforming the trial division primality test on a number.\n",
    "   \n",
    "    Trial Division Primality Test:  Given an input number n, check whether any prime integer m \n",
    "                                    from 2 to the square root of n evenly divides n.\n",
    "                                    If n is divisible by any m then n is composite, otherwise it is prime.\n",
    "    \"\"\"\n",
    "    \n",
    "    for divisor in range(2, int(number ** 0.5) + 1):\n",
    "        if number % divisor == 0:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without an Iterator\n",
    "Now that we have a function that tests whether or not a number is prime, let's get all of the prime numbers below `1,000,000` using a conventional `for` loop approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.77 µs\n",
      "The sum is:  37550402023\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "primes = []\n",
    "for n in range(2,1000000):\n",
    "    if primality_test(n):\n",
    "        primes.append(n)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "answer = sum(primes)\n",
    "\n",
    "print(\"The sum is:  {}\".format(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that was pretty straightforward. Unfortunately, we now have a list of `78,498` elements in our memory. That might not be limiting right now, but what if we wanted to get the sum of all the primes below a much larger number?\n",
    "\n",
    "\n",
    "So let's try this using an iterator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With an Iterator\n",
    "To turn our function `primality_test` into an iterator, we need to put it into a class and then define an `__iter__` and `__next__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Primes:\n",
    "    \n",
    "    def __init__(self, max_number):\n",
    "        self.max_number = max_number\n",
    "        self.number = 1\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        self.number += 1\n",
    "        if self.number >= self.max_number:\n",
    "            raise StopIteration\n",
    "        elif primality_test(self.number):\n",
    "            return self.number\n",
    "        else:\n",
    "            return self.__next__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37550402023"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "primes = Primes(1000000)\n",
    "sum(primes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the iterator approach saves us on memory, it might not have saved us on production time since we had to write a bit more code. Generators were introduced in part to meet this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='generator' ></a>\n",
    "## Creating a Generator\n",
    "If the body of a function contains the `yield` keyword, you have yourself a generator, even if it also contains a `return` statement! Let's define a simple one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_function():\n",
    "    print(\"Here we go!\") #you'll see why I included this print statement shortly.\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling a generator function returns a generator object, which is a special type of iterator. Once you have that generator object, you can loop through it (which implicitly calls the `__next__` method) or use the built-in `next()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we go!\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for n in generator:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we go!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what's going on up there?\n",
    "\n",
    "When we created a generator object, the generator function's code was not run all at once (notice how the print statement didn't execute with assigment `generator = generator_function()`). \n",
    "\n",
    "Only when we made calls to `next` (or `__next__`) did \"part of\" the generator function's code execute. I say \"part of\" because, as you can see, code execution in a generator stops once a `yield` statement has been reached. So the first `next` call yielded the first value. The second call to `next` then **resumed execution with the state in which the generator had after the first `yield`**. This is the fundamental difference between generators and regular functions: regular functions always start code execution at the top of the function definition and then discard their state once they `return` (or hit an `Exception`). Generators don't discard their state; they suspend it until `next` is called on them again.\n",
    "\n",
    "In short, generator functions return an object on which you can call `next`, such that for every call it returns the next value, until it raises a `StopIteration` exception, signaling that all of the values within the iterator have been generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-323ce5d717bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a Generator to Sum Primes\n",
    "Now that we have a handle on generators, let's rewrite our code to sum all those prime numbers using a generator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prime_sum_gen(max_number):\n",
    "    n = 1\n",
    "    while n < max_number:\n",
    "        n += 1\n",
    "        if primality_test(n):  # <-- there's the primality test function\n",
    "            yield n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "primes = prime_sum_gen(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37550402023"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "sum(primes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you have it! And, believe it or not, we can improve on that code with a **generator expression**, which we'll see next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Expressions\n",
    "Remember list comprehensions? Well, there are also [generator expressions](https://www.python.org/dev/peps/pep-0289/), which allow you to quickly and easily build a basic generator. To create them, you use parentheses instead of square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "gen = (n for n in range(5))\n",
    "for n in gen:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now to get the sum of all those primes using a generator comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37550402023"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(n for n in range(2,1000000) if primality_test(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id = 'takeaways'> </a>\n",
    "## Takeaways\n",
    "Here are the key things to remember about generators:\n",
    "\n",
    " - generators yield a series of values\n",
    " - the `yield` keyword coverts a function to a generator\n",
    " - A generator is just a special type of iterator, which means we can get its next value using `next()` or a loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'next'> </a>\n",
    "## What's Next\n",
    "Generators can also receive a value. This opens the door to writing [coroutines](https://en.wikipedia.org/wiki/Coroutine), which can be used for all sorts of cool things like asynchronous IO multitasking. We'll (maybe) tackle these topics in a later lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='applications'> </a>\n",
    "## Applications\n",
    "When your programs become larger, you'll ultimately want to make the output of one function the input to another. You might even want to do this several times. Chaining processes together like this is called piping. As we'll soon see, generators work will within this framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Lots of Large Files\n",
    "Generators are great for reading a large number of large files since they yield one data point at a time insteading of building up a list of data points in memory.\n",
    "\n",
    "To see this in action, we'll use both a loop (the conventional approach) and then a pipe of generators to extract a text pattern from a directory containing ten [Project Gutenberg](https://www.gutenberg.org/) books (which I've conventiently placed in an assets folder for you)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `for` Loop Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def pattern_finder(pattern=\"pattern\"):\n",
    "    matches = []\n",
    "    for dir_path, dir_names, file_names in os.walk('assets/'):\n",
    "        for file_name in file_names:\n",
    "            if file_name.endswith('.txt'):\n",
    "                for line in open(os.path.join(dir_path, file_name)):\n",
    "                    if pattern in line:\n",
    "                        matches.append(line)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most abundant were raked into a gridiron-pattern by fingers, these\n",
      "\n",
      "present mode. I never saw the mode. I have had a pattern in my hand.” He\n",
      "\n",
      "of wine, Madame Defarge herself picked out the pattern on her sleeve\n",
      "\n",
      "“A pretty pattern too!”\n",
      "\n",
      "pattern. Enough! Now, my dear Lucie,” drawing his arm soothingly round\n",
      "\n",
      "of his pate shaved into queer patterns, and three ornamental scars\n",
      "\n",
      "faces, and the pattern on their backs was the same as the rest of the\n",
      "\n",
      "One of those sprawling flamboyant patterns committing every artistic sin.\n",
      "\n",
      "There is a recurrent spot where the pattern lolls like a broken neck and\n",
      "\n",
      "This wallpaper has a kind of sub-pattern in a different shade, a\n",
      "\n",
      "follow that pattern about by the hour. It is as good as gymnastics, I\n",
      "\n",
      "time that I will follow that pointless pattern to some sort of a\n",
      "\n",
      "Behind that outside pattern the dim shapes get clearer every day.\n",
      "\n",
      "pattern. I don’t like it a bit. I wonder—I begin to think—I\n",
      "\n",
      "The faint figure behind seemed to shake the pattern, just as if she wanted\n",
      "\n",
      "trying to decide whether that front pattern and the back pattern really\n",
      "\n",
      "On a pattern like this, by daylight, there is a lack of sequence, a\n",
      "\n",
      "enough, but the pattern is torturing.\n",
      "\n",
      "The outside pattern is a florid arabesque, reminding one of a fungus. If\n",
      "\n",
      "worst of all by moonlight, it becomes bars! The outside pattern I mean,\n",
      "\n",
      "behind,—that dim sub-pattern,—but now I am quite sure it is a woman.\n",
      "\n",
      "By daylight she is subdued, quiet. I fancy it is the pattern that keeps\n",
      "\n",
      "Did not that sound innocent? But I know she was studying that pattern, and\n",
      "\n",
      "The front pattern does move—and no wonder! The woman behind shakes\n",
      "\n",
      "through that pattern—it strangles so; I think that is why it has so\n",
      "\n",
      "They get through, and then the pattern strangles them off and turns them\n",
      "\n",
      "If only that top pattern could be gotten off from the under one! I mean to\n",
      "\n",
      "moonlight, and that poor thing began to crawl and shake the pattern, I got\n",
      "\n",
      "And then when the sun came and that awful pattern began to laugh at me I\n",
      "\n",
      "sticks horribly and the pattern just enjoys it! All those strangled heads\n",
      "\n",
      "I suppose I shall have to get back behind the pattern when it comes night,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pattern_matches = pattern_finder()\n",
    "for match in pattern_matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our function above looped through all of the files in our assets directory. If the file name ended with `.txt`, the function opened the file and then looped through each line looking for the word `pattern`. If it saw that word, it appended the line to `matches`. Then we used a loop to print the matches.\n",
    "\n",
    "As you saw, this function worked well for our ten books. But that's just because we had a small number of small files. If we had more files -  and therefore more matches - our `matches` list might eventually exceed our memory limits. Another point to consider is that reading nested loops can quickly become difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Generator Pipeline Approach\n",
    "To pipe our program, we'll divide our process into three different components, each of which will rely on a generator:\n",
    " 1. generating the filenames\n",
    " 2. generating the lines\n",
    " 3. generating the matches\n",
    " \n",
    "The output of the first pipe will be the input of the second and so forth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most abundant were raked into a gridiron-pattern by fingers, these\n",
      "\n",
      "present mode. I never saw the mode. I have had a pattern in my hand.” He\n",
      "\n",
      "of wine, Madame Defarge herself picked out the pattern on her sleeve\n",
      "\n",
      "“A pretty pattern too!”\n",
      "\n",
      "pattern. Enough! Now, my dear Lucie,” drawing his arm soothingly round\n",
      "\n",
      "of his pate shaved into queer patterns, and three ornamental scars\n",
      "\n",
      "faces, and the pattern on their backs was the same as the rest of the\n",
      "\n",
      "One of those sprawling flamboyant patterns committing every artistic sin.\n",
      "\n",
      "There is a recurrent spot where the pattern lolls like a broken neck and\n",
      "\n",
      "This wallpaper has a kind of sub-pattern in a different shade, a\n",
      "\n",
      "follow that pattern about by the hour. It is as good as gymnastics, I\n",
      "\n",
      "time that I will follow that pointless pattern to some sort of a\n",
      "\n",
      "Behind that outside pattern the dim shapes get clearer every day.\n",
      "\n",
      "pattern. I don’t like it a bit. I wonder—I begin to think—I\n",
      "\n",
      "The faint figure behind seemed to shake the pattern, just as if she wanted\n",
      "\n",
      "trying to decide whether that front pattern and the back pattern really\n",
      "\n",
      "On a pattern like this, by daylight, there is a lack of sequence, a\n",
      "\n",
      "enough, but the pattern is torturing.\n",
      "\n",
      "The outside pattern is a florid arabesque, reminding one of a fungus. If\n",
      "\n",
      "worst of all by moonlight, it becomes bars! The outside pattern I mean,\n",
      "\n",
      "behind,—that dim sub-pattern,—but now I am quite sure it is a woman.\n",
      "\n",
      "By daylight she is subdued, quiet. I fancy it is the pattern that keeps\n",
      "\n",
      "Did not that sound innocent? But I know she was studying that pattern, and\n",
      "\n",
      "The front pattern does move—and no wonder! The woman behind shakes\n",
      "\n",
      "through that pattern—it strangles so; I think that is why it has so\n",
      "\n",
      "They get through, and then the pattern strangles them off and turns them\n",
      "\n",
      "If only that top pattern could be gotten off from the under one! I mean to\n",
      "\n",
      "moonlight, and that poor thing began to crawl and shake the pattern, I got\n",
      "\n",
      "And then when the sun came and that awful pattern began to laugh at me I\n",
      "\n",
      "sticks horribly and the pattern just enjoys it! All those strangled heads\n",
      "\n",
      "I suppose I shall have to get back behind the pattern when it comes night,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_filenames():\n",
    "    for dir_path, dir_names, file_names in os.walk('assets/'):\n",
    "        for file_name in file_names:\n",
    "            if file_name.endswith('.txt'):\n",
    "                yield open(os.path.join(dir_path, file_name))\n",
    "\n",
    "def generate_lines(files):\n",
    "    for fname in files:\n",
    "        for line in fname:\n",
    "            yield line\n",
    "\n",
    "def generate_matches(lines, pattern=None):\n",
    "    for line in lines:\n",
    "        if pattern in line:\n",
    "            yield line\n",
    "\n",
    "\n",
    "book_files = generate_filenames()\n",
    "book_lines = generate_lines(book_files)\n",
    "pattern_matches = generate_matches(book_lines, pattern = 'pattern')\n",
    "\n",
    "for match in pattern_matches:\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we did not use any extra variables to print our matches. Instead, we created a pipeline that fed its components via the iteration process one item at a time. `generate_matches` took in a generator object of all the book_lines of all of the `.txt` files. Similarly, `generate_lines` took in a generator object of all the filenames in a directory.\n",
    "\n",
    "The takeaway is that generator pipelines are a great way to break apart complex programs into smaller pieces."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
